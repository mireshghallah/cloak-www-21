{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "#from progress.bar import Bar\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import datacifar\n",
    "from alexnet import AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Preparing dataset %s' \"cifar 100\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "dataloader = datacifar.CIFAR100\n",
    "\n",
    "trainset = dataloader(root='../data', train=True, download=True, transform=transform_train, coarse=True)\n",
    "trainloader = data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "testset = dataloader(root='../data', train=False, download=False, transform=transform_test, coarse = True)\n",
    "testloader = data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)\n",
    "\n",
    "testloader2 = data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\n",
    "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(testloader, model, criterion):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    end = time.time()\n",
    "    #bar = Bar('Processing', max=len(testloader))\n",
    "    for batch_idx, (inputs, fine, targets) in enumerate(testloader):\n",
    "        # measure data loading time\n",
    "        #print(targets)\n",
    "        #print( coarse)\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1.item(), inputs.size(0))\n",
    "        top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        print( '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                    batch=batch_idx + 1,\n",
    "                    size=len(testloader),\n",
    "                    data=data_time.avg,\n",
    "                    bt=batch_time.avg,\n",
    "                    total=0,\n",
    "                    eta=0,\n",
    "                    loss=losses.avg,\n",
    "                    top1=top1.avg,\n",
    "                    top5=top5.avg,\n",
    "                    ))\n",
    "    #    bar.next()\n",
    "   # bar.finish()\n",
    "    return (losses.avg, top1.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch, increase = False, coef = 1):\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    end = time.time()\n",
    "\n",
    "    #bar = Bar('Processing', max=len(trainloader))\n",
    "    for batch_idx, (inputs, fine,targets) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        #print(targets)\n",
    "        \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        if (increase):\n",
    "            loss = criterion(outputs, targets) - coef*torch.log(torch.mean(model.intermed.scales()) ) +10\n",
    "        else:\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1.item(), inputs.size(0))\n",
    "        top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if(batch_idx%20 ==0):\n",
    "            print( '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(testloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=0,\n",
    "                        eta=0,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        ))\n",
    "            print(torch.mean(model_syn.intermed.scales()))\n",
    "\n",
    "            print(torch.max(model_syn.intermed.scales()))\n",
    "            print(torch.min(model_syn.intermed.scales()))\n",
    "\n",
    "    return (losses.avg, top1.avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stoch(testloader, model, criterion):\n",
    "    global best_acc\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    end = time.time()\n",
    "    #bar = Bar('Processing', max=len(testloader))\n",
    "    for batch_idx, (inputs, fine, targets) in enumerate(testloader2):\n",
    "        # measure data loading time\n",
    "        #print(targets)\n",
    "        #print( coarse)\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "\n",
    "        # compute output\n",
    "        outputs,_ = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1.item(), inputs.size(0))\n",
    "        top5.update(prec5.item(), inputs.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        if(batch_idx%1000 ==0):\n",
    "            print( '({batch}/{size}) Data: {data:.3f}s | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f} | top5: {top5: .4f}'.format(\n",
    "                        batch=batch_idx + 1,\n",
    "                        size=len(testloader),\n",
    "                        data=data_time.avg,\n",
    "                        bt=batch_time.avg,\n",
    "                        total=0,\n",
    "                        eta=0,\n",
    "                        loss=losses.avg,\n",
    "                        top1=top1.avg,\n",
    "                        top5=top5.avg,\n",
    "                        ))\n",
    "    #    bar.next()\n",
    "   # bar.finish()\n",
    "    return (losses.avg, top1.avg, top5.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stoch_avg(testloader, model, criterion, iterations = 5):\n",
    "    top1 =0\n",
    "    top5 = 0\n",
    "    for i in range (iterations):\n",
    "        _, t1, t5 = test_stoch(testloader, model, criterion)\n",
    "        top1+= t1\n",
    "        top5+= t5\n",
    "        \n",
    "    print(top1/iterations, top5/iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NoisyActivation(nn.Module):\n",
    "    def __init__(self,  given_locs, given_scales, min_scale, max_scale):\n",
    "        super(NoisyActivation, self).__init__()\n",
    "        size = given_scales.shape\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.given_locs = given_locs \n",
    "        self.given_scales = given_scales\n",
    "        self.locs = nn.Parameter(torch.Tensor(size).copy_(self.given_locs))         \n",
    "        self.rhos = nn.Parameter(torch.ones(size)-5) #-inf\n",
    "\n",
    "\n",
    "        self.normal = torch.distributions.normal.Normal(0,1)\n",
    "        self.rhos.requires_grad = True\n",
    "        self.locs.requires_grad = True\n",
    "        \n",
    "    def scales(self):\n",
    "        return (1.0 +torch.tanh(self.rhos))/2*(self.max_scale-self.min_scale) +self.min_scale             \n",
    "    \n",
    "    def sample_noise(self):\n",
    "        epsilon = self.normal.sample(self.rhos.shape)\n",
    "        return self.locs + self.scales() * epsilon\n",
    "                                 \n",
    "                               \n",
    "                            \n",
    "    def forward(self, input):\n",
    "        noise = self.sample_noise()\n",
    "        return (input) + noise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "class alexnet_syn(nn.Module):\n",
    "\n",
    "    def __init__(self, model_features, model_classifier, min_scale,max_scale, given_loc, given_scale):\n",
    "        super(alexnet_syn, self).__init__()\n",
    "        \n",
    "                                \n",
    "        #self.model_pt1 =  torch.nn.Sequential(*(list(model_features)[0:conv_layers[index]]))\n",
    "        self.intermed = NoisyActivation( given_loc, given_scale, min_scale, max_scale)\n",
    "        self.model_pt2 =  torch.nn.Sequential(*(list(model_features)))\n",
    "        self.model_pt3 = model_classifier\n",
    "        #self.components = components\n",
    "        for child in itertools.chain(self.model_pt2, self.model_pt3): \n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "            if isinstance(child, nn.modules.batchnorm._BatchNorm):\n",
    "                child.eval()\n",
    "                child.affine = False\n",
    "                child.track_running_stats = False\n",
    "                \n",
    "        self.intermed.rhos.reuires_grad = True\n",
    "        self.intermed.locs.reuires_grad = True\n",
    "                                 \n",
    "    def forward(self, img):\n",
    "                                 \n",
    "        \n",
    "        x = self.intermed(img)\n",
    "        noisy = x.detach()         \n",
    "        x = self.model_pt2(x)                    \n",
    "        x = x.view(img.size(0), -1)\n",
    "        x = self.model_pt3(x)                                 \n",
    "\n",
    "        return x, noisy\n",
    "    \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(20)\n",
    "print(model)\n",
    "model.load_state_dict(torch.load('old-20class', map_location=torch.device(device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = torch.zeros((3,32,32))\n",
    "scale = torch.ones((3,32,32))*0.01\n",
    "model_syn = alexnet_syn(model.features, model.classifier ,0.0001,1.0 ,mus, scale )\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "model_syn.load_state_dict(torch.load(\"old-20class-cloak\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(torch.mean(model_syn.intermed.scales()))\n",
    "\n",
    "print(torch.max(model_syn.intermed.scales()))\n",
    "print(torch.min(model_syn.intermed.scales()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(filter(lambda p: p.requires_grad, model_syn.parameters()))\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_syn.parameters(), lr= 0.001) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range (10):\n",
    "    train_loss, train_acc = train(trainloader, model_syn, criterion, optimizer, 100, False, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stoch_avg(testloader, model_syn, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, fine, labels) in enumerate(testloader2):\n",
    "    x= images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "imgs =np.reshape(np.squeeze(images.cpu().detach().numpy()), (1,-1))\n",
    "lbls = np.reshape(np.squeeze(labels.cpu().detach().numpy()), (1,-1))\n",
    "encoded_noise = model_syn.intermed.rhos.cpu().detach().numpy()\n",
    "encoded_original = model_syn.intermed.rhos.cpu().detach().numpy()\n",
    "image_noisy =np.reshape(np.squeeze(images.cpu().detach().numpy()), (1,-1))\n",
    "total_correct = 0\n",
    "\n",
    "model_syn.eval()\n",
    "model_syn.to(device)\n",
    "for i, (images, fine, labels) in enumerate(testloader2):\n",
    "    \n",
    "    #labels = (labels > 5).long()\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    imgs=np.concatenate((imgs,np.reshape(np.squeeze(images.cpu().detach().numpy()), (1,-1)) ))\n",
    "    np.save(\"original-image-mutual_info-20class-input-noise-cloak\", imgs)\n",
    "    lbls=np.concatenate((lbls,np.reshape(np.squeeze(labels.cpu().detach().numpy()), (1,-1)) ))\n",
    "    np.save(\"original-labels-mutual_info-20class-input-noise-cloak\", lbls)\n",
    "    \n",
    "    \n",
    "    x= images\n",
    "\n",
    "    x = model_syn.intermed(x)     \n",
    "  \n",
    "    \n",
    "    image_noisy=np.concatenate((image_noisy,np.reshape(np.squeeze(x.cpu().detach().numpy()), (1,-1)) ))\n",
    "    np.save(\"noisy-image-mutual_info-20class-input-noise-cloak\", image_noisy)\n",
    "\n",
    "    #print(imgs.shape, lbls.shape, encoded_original.shape, encoded_noise.shape, image_noisy.shape)\n",
    "    \n",
    "    x = model_syn.model_pt2(x)                    \n",
    "    x = x.view(images.size(0), -1)\n",
    "    output = model_syn.model_pt3(x)                                 \n",
    "\n",
    "\n",
    "    \n",
    "    #print(imgs.shape, image_noisy.shape)\n",
    "\n",
    "    pred = output.detach().max(1)[1]\n",
    "    total_correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "\n",
    "print('Test Avg. Loss: %f, Accuracy: %f' % (2, float(total_correct) / len(data_test)))\n",
    "return float(total_correct) / len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
