{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import itertools\n",
    "\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "from vgg16_2 import VGG_16_2\n",
    "\n",
    "\n",
    "import argparse\n",
    "from data_loader_withid_single_label_glasses import get_loader\n",
    "from data_loader_withid_single_label_glasses import get_dataset\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "celeba_image_dir = '/home/name/celeba/stargan/data/celeba/images'\n",
    "attr_path = '/home/name/celeba/stargan/data/celeba/list_attr_celeba.txt'\n",
    "id_path = '/home/name/celeba/stargan/data/celeba/identity_CelebA.txt'\n",
    "selected_attrs = ['Eyeglasses']\n",
    "celeba_crop_size = 224#178\n",
    "image_size = 224 #128\n",
    "batch_size = 30#100\n",
    "num_workers = 0\n",
    "mode1 = 'train' #test or train\n",
    "mode2 = 'test'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #\"cuda:0\" if torch.cuda.is_available() else \n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_loader_train, data_train = get_loader(celeba_image_dir, attr_path, id_path, selected_attrs,celeba_crop_size, image_size, batch_size,'CelebA', mode1, num_workers)\n",
    "celeba_loader_test, data_test = get_loader(celeba_image_dir, attr_path, id_path, selected_attrs,celeba_crop_size, image_size, batch_size,'CelebA', mode2, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_loader_test2, data_test2 = get_loader(celeba_image_dir, attr_path, id_path, selected_attrs,celeba_crop_size, image_size, 1,'CelebA', mode2, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_train))\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_label(model):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    size =0\n",
    "    for im, labels in celeba_loader_test:\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        preds, _ = model(im)\n",
    "        values, indices = preds.max(-1)\n",
    "        correct += indices.eq(labels).sum()\n",
    "        #print(correct, \"correct\")\n",
    "        #print(preds.shape)\n",
    "        #print (labels[0], indices[0])\n",
    "        #plt.figure()\n",
    "        #plt.imshow(im[0][0])#model_syn.intermed.scales()[0].detach().numpy()\n",
    "        #plt.show()\n",
    "        \n",
    "        del im\n",
    "        del preds\n",
    "        \n",
    "        del values\n",
    "        \n",
    "        print(correct)\n",
    "        size += len(labels)\n",
    "        del labels\n",
    "        print(float(correct)/float(size))\n",
    "        \n",
    "    print(size)\n",
    "    print(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_single_label_stoch(model):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    size =0\n",
    "    for im, labels in celeba_loader_test2:\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        preds, _ = model(im)\n",
    "        values, indices = preds.max(-1)\n",
    "        correct += indices.eq(labels).sum()\n",
    "        #print(correct, \"correct\")\n",
    "        #print(preds.shape)\n",
    "        #print (labels[0], indices[0])\n",
    "        #plt.figure()\n",
    "        #plt.imshow(im[0][0])#model_syn.intermed.scales()[0].detach().numpy()\n",
    "        #plt.show()\n",
    "        \n",
    "        del im\n",
    "        del preds\n",
    "        \n",
    "        del values\n",
    "        \n",
    "        #print(correct)\n",
    "        size += len(labels)\n",
    "        del labels\n",
    "        print(float(correct)/float(size))\n",
    "        \n",
    "    print(size)\n",
    "    print(correct)\n",
    "    return size,correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NoisyActivation(nn.Module):\n",
    "    def __init__(self,  given_locs, given_scales, min_scale, max_scale):\n",
    "        super(NoisyActivation, self).__init__()\n",
    "        size = given_scales.shape\n",
    "        self.min_scale = min_scale\n",
    "        self.max_scale = max_scale\n",
    "        self.given_locs = given_locs \n",
    "        self.given_scales = given_scales\n",
    "        self.locs = nn.Parameter(torch.Tensor(size).copy_(self.given_locs))         \n",
    "        self.rhos = nn.Parameter(torch.ones(size)-5) #-inf\n",
    "\n",
    "\n",
    "        self.normal = torch.distributions.normal.Normal(0,1)\n",
    "        self.rhos.requires_grad = True\n",
    "        self.locs.requires_grad = True\n",
    "        \n",
    "    def scales(self):\n",
    "        return (1.0 +torch.tanh(self.rhos))/2*(self.max_scale-self.min_scale) +self.min_scale             \n",
    "    \n",
    "    def sample_noise(self, mask):\n",
    "        epsilon = self.normal.sample(self.rhos.shape)*mask\n",
    "        return  self.locs + self.scales()*epsilon\n",
    "                                 \n",
    "                               \n",
    "                            \n",
    "    def forward(self, input, mask):\n",
    "        noise = self.sample_noise(mask)\n",
    "        return (input)*mask + noise\n",
    "\n",
    "\n",
    "\n",
    "class vgg_syn(nn.Module):\n",
    "\n",
    "    def __init__(self, model_features, model_classifier, min_scale,max_scale, given_locs, given_scale):\n",
    "        super(vgg_syn, self).__init__()\n",
    "        \n",
    "\n",
    "        self.intermed = NoisyActivation( given_locs, given_scale, min_scale, max_scale)\n",
    "        self.model_pt2 =  torch.nn.Sequential(*(list(model_features)))\n",
    "        self.model_pt3 = model_classifier\n",
    "        #self.components = components\n",
    "        for child in itertools.chain(self.model_pt2, self.model_pt3): #self.model_pt2 #(self.model_pt2, \n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "            if isinstance(child, nn.modules.batchnorm._BatchNorm):\n",
    "                child.eval()\n",
    "                child.affine = False\n",
    "                child.track_running_stats = False\n",
    "                \n",
    "        self.intermed.rhos.reuires_grad = True\n",
    "        self.intermed.locs.reuires_grad = True\n",
    "                                 \n",
    "    def forward(self, img, mask):\n",
    "                                 \n",
    "        img = img\n",
    "        x = self.intermed(img, mask)\n",
    "        noisy = x.detach()\n",
    "       \n",
    "        x = self.model_pt2(x)                    \n",
    "        x = x.view(img.size(0), -1)\n",
    "        x = self.model_pt3(x)                                 \n",
    "\n",
    "        return x, noisy\n",
    "    \n",
    "                                 \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversary(model, model_syn):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    size =0\n",
    "    for im, labels in celeba_loader_test2:\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        _, noisy = model_syn(im)\n",
    "        preds = model(noisy)\n",
    "        values, indices = preds.max(-1)\n",
    "        correct += indices.eq(labels).sum()\n",
    "        #print(correct, \"correct\")\n",
    "        #print(preds.shape)\n",
    "        #print (labels[0], indices[0])\n",
    "        #plt.figure()\n",
    "        #plt.imshow(im[0][0])#model_syn.intermed.scales()[0].detach().numpy()\n",
    "        #plt.show()\n",
    "\n",
    "        del im\n",
    "        del preds\n",
    "\n",
    "        del values\n",
    "\n",
    "        #print(correct)\n",
    "        size += len(labels)\n",
    "        del labels\n",
    "        print(float(correct)/float(size))\n",
    "\n",
    "    print(size)\n",
    "    print(correct)\n",
    "    return size,correct\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_mask(model, mask):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    size =0\n",
    "    for im, labels in celeba_loader_test:\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        im = im*mask\n",
    "        preds = model(im)\n",
    "        values, indices = preds.max(-1)\n",
    "        correct += indices.eq(labels).sum()\n",
    "        #print(correct, \"correct\")\n",
    "        #print(preds.shape)\n",
    "        #print (labels[0], indices[0])\n",
    "        #plt.figure()\n",
    "        #plt.imshow(im[0][0])#model_syn.intermed.scales()[0].detach().numpy()\n",
    "        #plt.show()\n",
    "        \n",
    "        del im\n",
    "        del preds\n",
    "        \n",
    "        del values\n",
    "        \n",
    "        print(correct)\n",
    "        size += len(labels)\n",
    "        del labels\n",
    "        print(float(correct)/float(size))\n",
    "        \n",
    "    print(size)\n",
    "    print(correct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_per_example_mask(model, mult_mask):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    size =0\n",
    "    for im, labels in celeba_loader_test2:\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        im_2 = im*mult_mask\n",
    "        preds = model(im_2)\n",
    "        values, indices = preds.max(-1)\n",
    "        correct += indices.eq(labels).sum()\n",
    "\n",
    "        \n",
    "        del im\n",
    "        del preds\n",
    "        #del im_2\n",
    "        del values\n",
    "        \n",
    "        size += len(labels)\n",
    "        del labels\n",
    "        print(float(correct)/float(size))\n",
    "        \n",
    "    print(size)\n",
    "    print(correct)\n",
    "    return size,correct\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train   noisy adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversary(model, model_syn, criterion, optimizer):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    size = 0\n",
    "    correcta = 0\n",
    "    model_syn.eval()\n",
    "    for i, (im, labels) in enumerate(celeba_loader_train):\n",
    "        #if (i ==1):\n",
    "         #   print (labels)\n",
    "        print(\"iteration no\", i)\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        _, noisy = model_syn(im)\n",
    "        output = model(noisy)\n",
    "        \n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        del im\n",
    "        del noisy\n",
    "        del _\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print (loss, \"loss\")\n",
    "        #preds = model(im)\n",
    "        values, indices = output.max(-1)\n",
    "        size += len(labels)\n",
    "        correcta += indices.eq(labels).sum()\n",
    "        correct = indices.eq(labels).sum()\n",
    "\n",
    "        \n",
    "        print(float(correcta)/float(size))\n",
    "            \n",
    "            \n",
    "    print(correcta, \"correct out of all\")\n",
    "    print(size)\n",
    "    return correct, size\n",
    "        #print(list(filter(lambda p: p.requires_grad, model.parameters()))[0][0])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adversary_mask(model, model_syn, criterion, optimizer, mask):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    size = 0\n",
    "    correcta = 0\n",
    "    model_syn.eval()\n",
    "    for i, (im, labels) in enumerate(celeba_loader_train):\n",
    "  \n",
    "        print(\"iteration no\", i)\n",
    "        im, labels = im.to(device), labels.to(device)\n",
    "        labels = labels.long().squeeze(1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        _, noisy = model_syn(im, mask)\n",
    "        output = model(noisy)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        del im\n",
    "        del noisy\n",
    "        del _\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print (loss, \"loss\")\n",
    "        #preds = model(im)\n",
    "        values, indices = output.max(-1)\n",
    "        size += len(labels)\n",
    "        correcta += indices.eq(labels).sum()\n",
    "        correct = indices.eq(labels).sum()\n",
    "\n",
    "        \n",
    "        print(float(correcta)/float(size))\n",
    "            \n",
    "            \n",
    "    print(correcta, \"correct out of all\")\n",
    "    print(size)\n",
    "    return correct, size\n",
    "        #print(list(filter(lambda p: p.requires_grad, model.parameters()))[0][0])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_glasses = VGG_16_2()\n",
    "\n",
    "model_glasses.load_state_dict(torch.load(\"celeba-glasses-2-class-96l4\",  map_location=device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_16_2()\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "mus = torch.zeros((3,224,224))\n",
    "scale = torch.ones((3,224,224))*0.001\n",
    "model_syn = vgg_syn(model.convnet, model.fc ,0, 5 ,mus, scale )\n",
    "model_syn.load_state_dict(torch.load(\"celeba-smiling-avg-cloak\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in itertools.chain(model_glasses.fc, model_glasses.convnet): #self.model_pt2 #(self.model_pt2, \n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = True\n",
    "print(model_glasses.fc[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = list(filter(lambda p: p.requires_grad, model_glasses.parameters()))\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_mask = torch.where(model_syn.intermed.scales()>4.5, torch.zeros(model_syn.intermed.scales().shape), torch.ones(model_syn.intermed.scales().shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =  0.0001  # 2 epochs 0.0001\n",
    "for epoch in range (1): # real\n",
    "   \n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model_glasses.parameters()), lr=lr, weight_decay=0)\n",
    "    cor, size = train_adversary_mask(model_glasses,model_syn, criterion, optimizer, mult_mask)\n",
    "    print (cor,size)\n",
    "\n",
    " \n",
    "\n",
    "    \n",
    "    #wd helps\n",
    "    if (epoch>  5):\n",
    "        lr  = 0.00001\n",
    "        print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}